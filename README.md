# rust-crud-api

## Description
A Rust-based CRUD API that connects to a MySQL database using Axum and SQLx.

## Features
- **Health Check Endpoint**: GET `/health` to check the API status.
- **User Management**: Create and retrieve users via the `/users` endpoint.

## Technologies Used
- Rust
- Axum
- SQLx
- MySQL
- Serde for serialization
- Argon2 for password hashing

## Project Structure
```
rust-crud-api/
    Cargo.toml
    LICENSE
    README.md
    src/
        app.rs
        main.rs
        routes.rs
        seed.rs
        config/
            mod.rs
        db/
            mod.rs
            mysql.rs
            user_repository.rs
        errors/
            api_error.rs
            mod.rs
        handlers/
            health.rs
            mod.rs
            user_handler.rs
        migrations/
            20260209165552_create_users.sql
            20260209165729_create_departments.sql
            20260209165754_create_user_departments.sql
            20260209165828_seed_data.sql
        models/
            mod.rs
            user.rs
```

## Setup
1. Clone the repository.
2. Run `cargo build` to build the project.
3. Set up your MySQL database and update the configuration in `config/mod.rs`.
4. Run migrations to set up the database schema.
5. Start the server with `cargo run`.

---

# üìä Performance experiments ‚Äî Axum API

Esta secci√≥n documenta lo observado durante las pruebas de latencia y tiempo de respuesta de la API, junto con las mejoras aplicadas y las que se implementar√°n posteriormente.

## 1) Metodolog√≠a de medici√≥n

Las mediciones se realizaron utilizando `curl` mostrando los tiempos detallados de la request:

```bash
curl -w "\nDNS: %{time_namelookup}s\
TCP: %{time_connect}s\
TLS: %{time_appconnect}s\
Pretransfer: %{time_pretransfer}s\
TTFB: %{time_starttransfer}s\
Total: %{time_total}s\n" \
-o /dev/null -s https://xxxx.ngrok-free.app/users
```

Para pruebas con compresi√≥n:

```bash
curl --compressed -w "\nDNS: %{time_namelookup}s\
TCP: %{time_connect}s\
TLS: %{time_appconnect}s\
Pretransfer: %{time_pretransfer}s\
TTFB: %{time_starttransfer}s\
Total: %{time_total}s\n" \
-o /dev/null -s https://xxxx.ngrok-free.app/users
```

Para pruebas locales:

```bash
curl -w "\nTTFB: %{time_starttransfer}s\
Total: %{time_total}s\n" \
-o /dev/null -s http://localhost:3000/users
```

## 2) Resultados obtenidos

### A) Antes de habilitar compresi√≥n (gzip)

El mayor tiempo se concentraba en la transferencia del payload (transfer + download).

Ejemplo representativo (~50 registros):

```
DNS: 0.285098s
TCP: 0.697037s
TLS: 1.012869s
Pretransfer: 1.014400s
TTFB: 1.819795s
Total: 1.820846s
```

**Observaci√≥n clave**

El TTFB era pr√°cticamente igual al tiempo total ‚Üí
el backend respond√≠a r√°pido, pero el tama√±o de la respuesta dominaba la latencia.

### B) Despu√©s de habilitar gzip

Al activar compresi√≥n HTTP:

* Reducci√≥n importante del tiempo total
* Reducci√≥n significativa del TTFB percibido
* El cuello de botella dej√≥ de ser el tama√±o de la respuesta

**Conclusi√≥n:**

> El problema principal no era el procesamiento sino el peso del JSON.

### C) Pruebas en local (sin red ni TLS)

En local el tiempo baj√≥ dr√°sticamente:

* La base de datos responde r√°pido
* La serializaci√≥n es r√°pida
* El overhead principal proviene de red + t√∫nel HTTPS

**Conclusi√≥n:**

> La API es r√°pida; el mayor costo est√° fuera del servidor (red + TLS + t√∫nel).

## 3) An√°lisis t√©cnico

Del desglose de tiempos:

| Etapa         | Impacto                      |
| ------------- | ---------------------------- |
| DNS           | Propio del t√∫nel             |
| TCP           | Handshake externo            |
| TLS           | Muy costoso en ngrok         |
| Backend       | R√°pido                       |
| Transferencia | Depend√≠a del tama√±o del JSON |

**Lo aprendido:**

1. El backend no era el problema principal
2. El tama√±o de respuesta afectaba m√°s que la query
3. TLS remoto domina el tiempo total
4. Compresi√≥n fue la mejora m√°s efectiva hasta ahora

## 4) Mejoras ya implementadas

* ‚úî Compresi√≥n gzip en respuestas
* ‚úî Validaci√≥n de tiempos por capas (red vs backend)
* ‚úî Confirmaci√≥n de performance real en entorno local
* ‚úî Comparaci√≥n directa local vs t√∫nel HTTPS

## 5) Pr√≥ximas optimizaciones (plan de mejora)

### A) Optimizaci√≥n de payload

Reducir el tama√±o de respuesta:

* DTOs espec√≠ficos por endpoint
* Evitar columnas innecesarias
* Paginaci√≥n obligatoria
* Evitar `SELECT *`
* Posible uso de `serde(skip_serializing_if)`

### B) Optimizaci√≥n de consultas SQL

* √çndices en filtros frecuentes
* Evitar OFFSET grandes
* Implementar paginaci√≥n por cursor (keyset pagination)

**Objetivo:**

> evitar escaneo completo de tabla

### C) Mejora de serializaci√≥n

Opciones a evaluar:

* JSON m√°s compacto
* MessagePack (evaluaci√≥n futura)
* Streaming response para listas grandes

### D) Mejora de conexi√≥n

* Pool tuning
* Prepared statements cache
* Mantener conexiones calientes

### E) Reducci√≥n del impacto TLS

El t√∫nel HTTPS agrega gran parte de la latencia.

Por lo tanto las m√©tricas v√°lidas de rendimiento backend ser√°n:

> siempre las pruebas locales

Las pruebas v√≠a t√∫nel solo se usar√°n para latencia real de usuario.

## 6) Conclusi√≥n general

Actualmente:

* El backend es r√°pido
* La DB responde r√°pido
* El mayor costo est√° en red + TLS + tama√±o de respuesta

Despu√©s de gzip:

> La performance dej√≥ de depender del peso del JSON y pas√≥ a depender principalmente de la red.

Las siguientes optimizaciones apuntan a:

1. Reducir tama√±o l√≥gico del payload
2. Optimizar paginaci√≥n
3. Evitar scans completos
4. Preparar la API para datasets grandes

## Estado actual

* ‚úî Compresi√≥n implementada
* ‚úî Performance local validada
* ‚úî Cuello de botella identificado

## Pendiente

* ‚¨ú Cursor pagination
* ‚¨ú √çndices SQL
* ‚¨ú DTO optimizados
* ‚¨ú Serializaci√≥n optimizada
* ‚¨ú Pool tuning

---

## License
This project is licensed under the MIT License.